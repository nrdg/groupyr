{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Sparse Group Lasso for grouped sparse signals\n\nEstimates a Sparse Group Lasso model on a simulated sparse signal with high\ngroup-level sparsity. The prediction is compared to the ground truth and to\nthe results of a Lasso model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import groupyr as gpr\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.metrics import r2_score, mean_squared_error\nfrom sklearn.model_selection import train_test_split\n\n\nX, y, groups, coef = gpr.datasets.make_group_regression(\n    n_samples=400,\n    n_groups=50,\n    n_informative_groups=5,\n    n_features_per_group=20,\n    n_informative_per_group=18,\n    noise=500,\n    coef=True,\n    random_state=10,\n)\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.25, random_state=10\n)\n\n# Fit an SGL model for this data\ncv = KFold(random_state=1729)\nsgl = gpr.SGLCV(\n    groups=groups, cv=cv, l1_ratio=[0.0, 1.0], tuning_strategy=\"bayes\", n_bayes_iter=50\n).fit(X_train, y_train)\n\n# Fit a Lasso model on this data\ncv = KFold(random_state=1729)\nlasso = LassoCV(cv=cv).fit(X_train, y_train)\n\n# Print model performance\nprint(\"Lasso performance:\")\nprint(\n    \"train: R^2 = {0:5.3f}, RMSE = {1:7.3f}\".format(\n        r2_score(y_train, lasso.predict(X_train)),\n        np.sqrt(mean_squared_error(y_train, lasso.predict(X_train))),\n    )\n)\nprint(\n    \"test:  R^2 = {0:5.3f}, RMSE = {1:7.3f}\".format(\n        r2_score(y_test, lasso.predict(X_test)),\n        np.sqrt(mean_squared_error(y_test, lasso.predict(X_test))),\n    )\n)\nprint(\"\\nSGL performance:\")\nprint(\n    \"train: R^2 = {0:5.3f}, RMSE = {1:7.3f}\".format(\n        r2_score(y_train, sgl.predict(X_train)),\n        np.sqrt(mean_squared_error(y_train, sgl.predict(X_train))),\n    )\n)\nprint(\n    \"test:  R^2 = {0:5.3f}, RMSE = {1:7.3f}\".format(\n        r2_score(y_test, sgl.predict(X_test)),\n        np.sqrt(mean_squared_error(y_test, sgl.predict(X_test))),\n    )\n)\n\n# Plot predicted values\nplt.plot(y_test, sgl.predict(X_test), marker=\"o\", ls=\"\", alpha=0.7, label=\"SGL\")\nplt.plot(y_test, lasso.predict(X_test), marker=\"o\", ls=\"\", alpha=0.7, label=\"LASSO\")\n\nmax_val = np.max(\n    [np.max(y_test), np.max(lasso.predict(X_test)), np.max(sgl.predict(X_test))]\n)\nmin_val = np.min(\n    [np.min(y_test), np.min(lasso.predict(X_test)), np.min(sgl.predict(X_test))]\n)\n\nplt.plot([min_val, max_val], [min_val, max_val], ls=\":\", lw=2, color=\"black\")\nplt.xlabel(\"Target values\")\nplt.ylabel(\"Predicted values\")\n\nplt.legend()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}